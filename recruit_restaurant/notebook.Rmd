---
title: "test_recruit"
author: "Simon Brunner"
date: "21 December 2017"
output: html_document
---

```{r}
source('../../kaggle_sourcer.R', chdir = T)
```

```{r}
model_dat = tbl_df(fread('output/main_tbl.csv')) %>%
  mutate(target_month=factor(target_month),
         target_year=factor(target_year),
         target_weekday=factor(target_weekday),
         air_genre_name=factor(air_genre_name),
         air_area_name=factor(air_area_name),
         holiday_flg=factor(holiday_flg))
model_dat

target_cols = c('target_day', 'target_month', 'target_weekday', 'target_year', 'air_genre_name', 'air_area_name', 'latitude', 'longitude', 'holiday_flg')
```

### Load submission template
```{r}
sub_templ = tbl_df(fread('input/sample_submission.csv'))
```


```{r}
grid = 10^seq(10, -2, length = 100)
#options(na.action="na.pass")
idx_train = which(model_dat$test==0)
idx_modtrain = sample(x=c(1:length(idx_train)), size = length(idx_train)/2)
x = model.matrix(visitors~., model_dat[,c(target_cols, 'visitors')])
y = model_dat$visitors
y = y/max(y)
lasso_mod = glmnet(x=x[idx_train[idx_modtrain],],
                   y=y[idx_train[idx_modtrain]],alpha = 1)
bestlam = min(lasso_mod$lambda)
plot(lasso_mod)
```

Predictions
```{r}
y_fit = predict(lasso_mod, s=bestlam, newx=x[idx_train[-idx_modtrain],])
plot(y[idx_train[-idx_modtrain]], y_fit)

RMSE = sqrt(mean((y[idx_train[-idx_modtrain]] - y_fit)^2))
RMSE
```

## Try with XGboost
```{r}
library(xgboost)

x = model.matrix(visitors~., model_dat[,c(target_cols, 'visitors')])
y = model_dat$visitors/max(model_dat$visitors)
bst <- xgboost(data = x[idx_train[idx_modtrain], ],
               label = y[idx_train[idx_modtrain]], max_depth = 3, eta = 1, nrounds = 200,
               nthread = 2, objective = "reg:logistic", eval_metric='rmse')
xg_pred = predict(bst, x[idx_train[-idx_modtrain],])
```

```{r}
plt_dat = tbl_df(data.frame(known=y[idx_train[-idx_modtrain]], predicted=xg_pred))

ggplot(plt_dat, aes(x=known, y=predicted)) + geom_point(size=0.2, alpha=0.1)

```

```{r}
RMSE = sqrt(mean((y[idx_train[-idx_modtrain]] - xg_pred)^2))
RMSE
```


## Try clustering locations rather than using coordinates
### FYI: there are actually just 829 stores...
```{r}
length(unique(model_dat$air_store_id))
```

### Also, lots of areas have very few restaurants...
We could probably do with the main stores and for the rest replace them with the cluster IDs
```{r}
plt_dat = model_dat %>% dplyr::select(air_store_id, air_area_name) %>% 
  group_by(air_area_name) %>% summarise(num_occ = n() ) %>% ungroup()
plt_dat$air_area_name = factor(plt_dat$air_area_name, ordered=T,
                               levels=(plt_dat$air_area_name[order(plt_dat$num_occ, decreasing = T)]))
ggplot(plt_dat, aes(x=air_area_name, y=num_occ)) + geom_bar(stat='identity') +
  coord_flip()
```
We could keep the top quarter and toss the rest.

### Are there areas with exceptionally many visitors?
```{r}
plt_dat = model_dat %>% 
  group_by(air_area_name) %>% summarise(num_occ = n(), med_visit = median(visitors) ) %>% ungroup()
plt_dat$air_area_name = factor(plt_dat$air_area_name, ordered=T,
                               levels=(plt_dat$air_area_name[order(plt_dat$med_visit, decreasing = T)]))
ggplot(model_dat, aes(x=air_area_name, y=visitors)) + geom_boxplot() +
  coord_flip()
```

The stores occur in rather obvious clusters, possibly along a street.
```{r}
ggplot(model_dat, aes(x=latitude, y=longitude)) + geom_point(size=0.2, alpha=0.6)
```

But where are visitor numbers greatest? Looks like location is not very indicative of visitor numbers, by itself?
```{r}
ggplot(model_dat, aes(x=latitude, y=longitude, color=log2(visitors))) + geom_point(size=0.2, alpha=0.6) +
  scale_color_gradient2(low='white', mid='blue', high='red')
```

### Try k-means clustering
...which works pretty well.
```{r}
x_km = as.matrix(model_dat[,c('latitude', 'longitude')])
km = kmeans(x_km, 5, nstart=20)

plt_dat = model_dat
plt_dat$km_assign = km$cluster

ggplot(plt_dat, aes(x=latitude, y=longitude, color=factor(km_assign))) + geom_point(size=0.2, alpha=0.6)
```

#### Just quickly want to see if there are any noticeable differences in visitor numbers between clusters
... Only once the genre is taken into account.
This should probably be used as an interaction term.
```{r}
ggplot(plt_dat, aes(x=factor(km_assign), y=visitors)) + geom_boxplot() +
  scale_y_log10() +
  facet_wrap(~air_genre_name)
```

### Create new feature based on both top area names and clusters
```{r}

```


### Let's try to use XGboost without latitude and longitude, but with location clusters!

```{r}
model_dat$location_clust = factor(km$cluster)
```

```{r}
library(xgboost)
target_cols = c('target_day', 'target_month', 'target_weekday', 'target_year', 'air_genre_name', 'air_area_name', 'holiday_flg', 'location_clust', 'longitude', 'latitude')

x = model.matrix(visitors~., model_dat[,c(target_cols, 'visitors')])

#x = sparse.model.matrix(is_churn~.-1, data = tree_dat %>% dplyr::select(-msno, -modtrain, -train, -fee_per_day, -ever_cancelled))
#x = sparse.model.matrix(is_churn~.-1, data = tree_dat %>% dplyr::select(-msno, -modtrain, -train))
max_visit = max(model_dat$visitors)
y = log1p(model_dat$visitors/max_visit)
bst <- xgboost(data = x[idx_train[idx_modtrain], ],
               label = y[idx_train[idx_modtrain]], max_depth = 3, eta = 1, nrounds = 100,
               nthread = 2, objective = "reg:logistic", eval_metric='rmse')
xg_pred = predict(bst, x[idx_train[-idx_modtrain],])
```

Check importance
```{r}
importance <- xgb.importance(feature_names = colnames(x), bst)
importance
```

```{r}
tbl_df(data.frame(known=y[idx_train[-idx_modtrain]], predicted=xg_pred, untrafo=model_dat$visitors)) %>%
  ggplot(aes(x=known, y=predicted)) + geom_point(size=0.2, alpha=0.1)

```

### Minor, if any, performance improvements.
```{r}
RMSE = sqrt(mean((y[idx_train[-idx_modtrain]] - xg_pred)^2))
RMSE
```

### Prep submission
```{r}
sub_pred = predict(bst, x)
sub_dat = model_dat
sub_dat$visitors = expm1(sub_pred) * max_visit
sub_dat = sub_dat %>% 
  mutate(id = paste(air_store_id, paste(target_year, sprintf("%02d", target_month), sprintf("%02d", target_day), sep='-'), sep='_')) %>%
  filter(test==1) %>%
  dplyr::select(id, visitors)
sub_dat = left_join(sub_templ %>% dplyr::select(id), sub_dat, by='id')
fwrite(sub_dat, 'submissions/xg_boost2_log_trafo.csv')
```

## Try ARIMA

### Average (median) each day across all restaurants
```{r}
dat_arima_avg = model_dat %>%
  mutate(r_date = as.Date(paste(target_year, target_month, target_day, sep='-'), format='%Y-%m-%d')) %>%
  group_by(r_date) %>%
  summarise(avg_visits = median(visitors)) %>% ungroup()

ggplot(dat_arima_avg, aes(x=r_date, y=avg_visits)) + geom_line()
```

### Fit ARIMA
```{r}
arima_train = dat_arima_avg %>% filter(r_date < '2017-02-01')
arima_test = dat_arima_avg %>% filter(r_date >= '2017-02-01', r_date < '2017-04-23')

m <- arima(arima_train$avg_visits, order=c(2,1,2), seasonal= list(order=c(1,1,1), period=7))
y_pred <- predict(m, dim(arima_test)[1])
y_pred_tbl = tibble(visit_preds = as.numeric(y_pred$pred), r_date = arima_test$r_date)

left_join(dat_arima_avg, y_pred_tbl, by='r_date') %>%
  gather(key = 'visit_type', value='visits', c(avg_visits, visit_preds)) %>%
  ggplot(aes(x=r_date, y=visits, color=visit_type)) + geom_line()

RMSE = sqrt(mean((y_pred_tbl$visit_preds - arima_test$avg_visits)^2))
RMSE

```
